{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab07: Decision Trees\n",
    "## Mehmet Gönen\n",
    "### November 27, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def safelog2(x):\n",
    "    if x == 0:\n",
    "        return (0)\n",
    "    else:\n",
    "        return (np.log2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into memory\n",
    "data_set = np.genfromtxt(\"lab07_data_set.csv\", delimiter = \",\")\n",
    "\n",
    "# get X and y values\n",
    "X = data_set[:,[0, 1, 2, 3]]\n",
    "y = data_set[:,4].astype(int)\n",
    "\n",
    "# get number of classes, number of samples, and number of features\n",
    "K = np.max(y)\n",
    "N = X.shape[0]\n",
    "D = X.shape[1]\n",
    "\n",
    "# get train and test splits\n",
    "train_indices = np.concatenate((np.arange(0, 25), np.arange(50, 75), np.arange(100, 125)))\n",
    "test_indices = np.setdiff1d(range(N), train_indices)\n",
    "\n",
    "X_train = X[train_indices,:]\n",
    "y_train = y[train_indices]\n",
    "X_test = X[test_indices,:]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "# get numbers of train and test samples\n",
    "N_train = len(y_train)\n",
    "N_test = len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create necessary data structures\n",
    "node_indices = {}\n",
    "is_terminal = {}\n",
    "need_split = {}\n",
    "\n",
    "node_features = {}\n",
    "node_splits = {}\n",
    "node_frequencies = {}\n",
    "\n",
    "# put all training instances into the root node\n",
    "node_indices[1] = np.array(range(N_train))\n",
    "is_terminal[1] = False\n",
    "need_split[1] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning algorithm\n",
    "while True:\n",
    "    # find nodes that need splitting\n",
    "    split_nodes = [key for key, value in need_split.items() if value == True]\n",
    "    # check whether we reach all terminal nodes\n",
    "    if len(split_nodes) == 0:\n",
    "        break\n",
    "    # find best split positions for all nodes\n",
    "    for split_node in split_nodes:\n",
    "        data_indices = node_indices[split_node]\n",
    "        need_split[split_node] = False\n",
    "        node_frequencies[split_node] = [sum(y_train[data_indices] == c + 1) for c in range(K)]\n",
    "        if len(np.unique(y_train[data_indices])) == 1:\n",
    "            is_terminal[split_node] = True\n",
    "        else:\n",
    "            is_terminal[split_node] = False\n",
    "\n",
    "            best_scores = np.repeat(0.0, D)\n",
    "            best_splits = np.repeat(0.0, D)\n",
    "            for d in range(D):\n",
    "                unique_values = np.sort(np.unique(X_train[data_indices, d]))\n",
    "                split_positions = (unique_values[1:len(unique_values)] + unique_values[0:(len(unique_values) - 1)]) / 2\n",
    "                split_scores = np.repeat(0.0, len(split_positions))\n",
    "                for s in range(len(split_positions)):\n",
    "                    left_indices = data_indices[X_train[data_indices, d] < split_positions[s]]\n",
    "                    right_indices = data_indices[X_train[data_indices, d] >= split_positions[s]]\n",
    "                    split_scores[s] = -len(left_indices) / len(data_indices) * np.sum([np.mean(y_train[left_indices] == c + 1) * safelog2(np.mean(y_train[left_indices] == c + 1)) for c in range(K)]) - len(right_indices) / len(data_indices) * np.sum([np.mean(y_train[right_indices] == c + 1) * safelog2(np.mean(y_train[right_indices] == c + 1)) for c in range(K)])\n",
    "                best_scores[d] = np.min(split_scores)\n",
    "                best_splits[d] = split_positions[np.argmin(split_scores)]\n",
    "            # decide where to split on which feature\n",
    "            split_d = np.argmin(best_scores)\n",
    "\n",
    "            node_features[split_node] = split_d\n",
    "            node_splits[split_node] = best_splits[split_d]\n",
    "            \n",
    "            # create left node using the selected split\n",
    "            left_indices = data_indices[X_train[data_indices, split_d] < best_splits[split_d]]\n",
    "            node_indices[2 * split_node] = left_indices\n",
    "            is_terminal[2 * split_node] = False\n",
    "            need_split[2 * split_node] = True\n",
    "      \n",
    "            # create right node using the selected split\n",
    "            right_indices = data_indices[X_train[data_indices, split_d] >= best_splits[split_d]]\n",
    "            node_indices[2 * split_node + 1] = right_indices\n",
    "            is_terminal[2 * split_node + 1] = False\n",
    "            need_split[2 * split_node + 1] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x3 < 2.60'] => [25, 0, 0]\n",
      "['x3 >= 2.60' 'x4 < 1.65' 'x3 < 4.95'] => [0, 24, 0]\n",
      "['x3 >= 2.60' 'x4 < 1.65' 'x3 >= 4.95'] => [0, 0, 1]\n",
      "['x3 >= 2.60' 'x4 >= 1.65' 'x3 >= 4.85'] => [0, 0, 23]\n",
      "['x3 >= 2.60' 'x4 >= 1.65' 'x3 < 4.85' 'x1 < 5.40'] => [0, 0, 1]\n",
      "['x3 >= 2.60' 'x4 >= 1.65' 'x3 < 4.85' 'x1 >= 5.40'] => [0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# extract rules\n",
    "terminal_nodes = [key for key, value in is_terminal.items() if value == True]\n",
    "for terminal_node in terminal_nodes:\n",
    "    index = terminal_node\n",
    "    rules = np.array([])\n",
    "    while index > 1:\n",
    "        parent = np.floor(index / 2)\n",
    "        if index % 2 == 0:\n",
    "            # if node is left child of its parent\n",
    "            rules = np.append(rules, \"x{:d} < {:.2f}\".format(node_features[parent] + 1, node_splits[parent]))\n",
    "        else:\n",
    "            # if node is right child of its parent\n",
    "            rules = np.append(rules, \"x{:d} >= {:.2f}\".format(node_features[parent] + 1, node_splits[parent]))\n",
    "        index = parent\n",
    "    rules = np.flip(rules)\n",
    "    print(\"{} => {}\".format(rules, node_frequencies[terminal_node]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test        1   2   3\n",
      "y_predicted            \n",
      "1            25   0   0\n",
      "2             0  25   0\n",
      "3             0   0  25\n"
     ]
    }
   ],
   "source": [
    "# traverse tree for training data points\n",
    "y_predicted = np.repeat(0, N_train)\n",
    "for i in range(N_train):\n",
    "    index = 1\n",
    "    while True:\n",
    "        if is_terminal[index] == True:\n",
    "            y_predicted[i] = np.argmax(node_frequencies[index]) + 1\n",
    "            break\n",
    "        else:\n",
    "            if X_train[i, node_features[index]] < node_splits[index]:\n",
    "                index = index * 2\n",
    "            else:\n",
    "                index = index * 2 + 1\n",
    "confusion_matrix = pd.crosstab(y_predicted, y_test, rownames = ['y_predicted'], colnames = ['y_test'])\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test        1   2   3\n",
      "y_predicted            \n",
      "1            25   0   0\n",
      "2             0  23   2\n",
      "3             0   2  23\n"
     ]
    }
   ],
   "source": [
    "# traverse tree for test data points\n",
    "y_predicted = np.repeat(0, N_test)\n",
    "for i in range(N_test):\n",
    "    index = 1\n",
    "    while True:\n",
    "        if is_terminal[index] == True:\n",
    "            y_predicted[i] = np.argmax(node_frequencies[index]) + 1\n",
    "            break\n",
    "        else:\n",
    "            if X_test[i, node_features[index]] < node_splits[index]:\n",
    "                index = index * 2\n",
    "            else:\n",
    "                index = index * 2 + 1\n",
    "confusion_matrix = pd.crosstab(y_predicted, y_test, rownames = ['y_predicted'], colnames = ['y_test'])\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
